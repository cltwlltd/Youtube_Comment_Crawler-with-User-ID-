{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_comments(url):\n",
    "    data1=[]\n",
    "    data2=[]\n",
    "    # Warning: need to change the location of the path where you saved the chrome driver\n",
    "    driver = Chrome(executable_path=r'C:\\Program Files\\chromedriver.exe')  \n",
    "    wait = WebDriverWait(driver,5)\n",
    "    driver.get(url)\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Pause the video to avoid \"autoplay next video\"\n",
    "    videoplayer = driver.find_element_by_id('movie_player')\n",
    "    videoplayer.send_keys(Keys.SPACE) #hits space\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Save variable names\n",
    "    comment_section = driver.find_element_by_xpath('//*[@id=\"comments\"]')\n",
    "    vidTitle = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR,\"h1.title yt-formatted-string\"))).text\n",
    "\n",
    "    # Scroll to view the comment section\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", comment_section)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # Scroll all the way down to the bottom\n",
    "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down 'til \"next load\"\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        # Wait to load everything thus far\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # One last scroll just in case\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "\n",
    "    # Scrape each author name\n",
    "    for body in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#author-text\"))):\n",
    "        data1.append(body.text)\n",
    "\n",
    "    # Scrape each comment\n",
    "    for body in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
    "        data2.append(body.text)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    # Merge each author name with corresponding comment\n",
    "    mergedData = ['&&&&&&'.join(x) for x in zip(data1,data2)]\n",
    "    return mergedData, vidTitle\n",
    "            \n",
    "# html key for the Id and the comment:\n",
    "# main\n",
    "# author-text\n",
    "# comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(scrapedData, videoTitle):\n",
    "    # Convert a list to a dataframe\n",
    "    df = pd.DataFrame(scrapedData, columns=['chunk'])\n",
    "\n",
    "    # Add column names\n",
    "    df[['User ID','Comment']] = df['chunk'].str.split(\"&&&&&&\",expand=True,)\n",
    "\n",
    "    # Drop unnecessary column(s)\n",
    "    df = df.drop(columns=['chunk'])\n",
    "    \n",
    "    # Save the data as a csv file\n",
    "    videoTitle = videoTitle.translate({ord(c): None for c in '\\/:*?\"<>|'})\n",
    "    df.to_csv(videoTitle + '.csv', index=False)\n",
    "    print(\"Showing the first five comments as an example\")\n",
    "    print(\"The order of the comments shown here may not be the same as what you see in the Youtube comment section\")\n",
    "    print('Go to where you saved this .ipynb file and you will see a new csv file named as the title of the Youtube video')\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the link of the youtube video and paste it in the quotes\n",
    "url = \"https://www.youtube.com/watch?v=hrWd_-jDVB0&ab_channel=BBCEarthBBCEarthVerified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the first five comments as an example\n",
      "The order of the comments shown here may not be the same as what you see in the Youtube comment section\n",
      "Go to where you saved this .ipynb file and you will see a new csv file named as the title of the Youtube video\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Gotta love when cheetah families  stick togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prajjwal Tiwari</td>\n",
       "      <td>Mad respect for the bull! Man.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robbert snyman</td>\n",
       "      <td>Man that lion is so focused there's a fly on h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahil Joshi</td>\n",
       "      <td>The bull was the real fighter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DYH</td>\n",
       "      <td>The stamina of those wolves and hare is amazing!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           User ID                                            Comment\n",
       "0                   Gotta love when cheetah families  stick togeth...\n",
       "1  Prajjwal Tiwari                     Mad respect for the bull! Man.\n",
       "2   robbert snyman  Man that lion is so focused there's a fly on h...\n",
       "3      Sahil Joshi                      The bull was the real fighter\n",
       "4              DYH   The stamina of those wolves and hare is amazing!"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to create a csv file!\n",
    "scrapedData, videoTitle = scrape_comments(url)\n",
    "transform(scrapedData, videoTitle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawler: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the link of the youtube video and paste it in the quotes\n",
    "url = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to create a csv file!\n",
    "scrapedData, videoTitle = scrape_comments(url)\n",
    "transform(scrapedData, videoTitle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
